{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSA4265 Assignment 2: RAG Generation\n",
    "\n",
    "With the large availability of news available today from different agencies, it is increasingly difficult for investors to spend time to look through all news articles in order to obtain the answer that they are looking for. \n",
    "\n",
    "Therefore, the goal of this assignment is to create a search engine that summarises key information about the recent stock data in order to have a better context of the stock such that investors can make a more informed decision about the performance of the stock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Extraction\n",
    "\n",
    "The following section describes the data extraction process and generation of the labelled dataframe. The tickers used for analysis are that of Apple Inc. (AAPL) and Tesla stocks (TSLA). The data obtained was sourced from Refinitiv Workspace, and the code to extract the dataframes were all copied and pasted from its in-built CodeBook. News headlines were limited to top deals for digital finance, corporate finance, and overall news about the stock itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wjlwi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\refinitiv\\data\\eikon\\__init__.py:15:FutureWarning: The refinitiv.data.eikon module will be removed in future library version v2.0. Please install and use the 'eikon' Python library instead or migrate your code to the Refinitiv/LSEG Data Library\n"
     ]
    }
   ],
   "source": [
    "import refinitiv.data as rd\n",
    "from refinitiv.data.content import news\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime,timedelta\n",
    "import time\n",
    "import warnings\n",
    "import refinitiv.data.eikon as ek\n",
    "from IPython.display import HTML\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<refinitiv.data.session.Definition object at 0x2969ae560e0 {name='workspace'}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd.open_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>storyId</th>\n",
       "      <th>sourceCode</th>\n",
       "      <th>ric</th>\n",
       "      <th>full_story</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versionCreated</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-02-27 13:00:00</th>\n",
       "      <td>RPT-BREAKINGVIEWS-GM illuminates good times be...</td>\n",
       "      <td>urn:newsml:reuters.com:20250227:nL3N3PH1P3:5</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>(The author is a Reuters Breakingviews columni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-25 12:52:47</th>\n",
       "      <td>Tesla to acquire parts of insolvent German par...</td>\n",
       "      <td>urn:newsml:reuters.com:20250225:nL5N3PG0Y9:7</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>* \\n      Acquisition includes 300 staff, excl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-25 01:10:32</th>\n",
       "      <td>RPT-BREAKINGVIEWS-Nissan offers suitors daunti...</td>\n",
       "      <td>urn:newsml:reuters.com:20250225:nL3N3PG036:3</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>(The author is a Reuters Breakingviews columni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-24 12:00:00</th>\n",
       "      <td>RPT-BREAKINGVIEWS-Nissan offers suitors daunti...</td>\n",
       "      <td>urn:newsml:reuters.com:20250224:nL3N3PF0DU:4</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>(The author is a Reuters Breakingviews columni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-21 13:55:05</th>\n",
       "      <td>UPDATE 6-Japan seeks Tesla investment in Nissa...</td>\n",
       "      <td>urn:newsml:reuters.com:20250221:nL3N3PC0GR:2</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>* \\n      Japanese group draws up plans for Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 15:03:57</th>\n",
       "      <td>US STOCKS-Wall St subdued as markets await tar...</td>\n",
       "      <td>urn:newsml:reuters.com:20250214:nL4N3P515Y:5</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>AAPL.O</td>\n",
       "      <td>(For a Reuters live blog on U.S., UK and Europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 14:04:36</th>\n",
       "      <td>US STOCKS-Wall St set for subdued open as mark...</td>\n",
       "      <td>urn:newsml:reuters.com:20250214:nL4N3P512O:5</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>AAPL.O</td>\n",
       "      <td>(For a Reuters live blog on U.S., UK and Europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 12:31:59</th>\n",
       "      <td>US STOCKS-Futures slip as markets await tariff...</td>\n",
       "      <td>urn:newsml:reuters.com:20250214:nL4N3P50XC:5</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>AAPL.O</td>\n",
       "      <td>(For a Reuters live blog on U.S., UK and Europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 11:50:37</th>\n",
       "      <td>REFILE-FACTBOX-China's AI firms take spotlight...</td>\n",
       "      <td>urn:newsml:reuters.com:20250214:nL1N3P50BI:1</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>AAPL.O</td>\n",
       "      <td>(Refiles to correct transposed letters in Doub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-02-14 08:57:56</th>\n",
       "      <td>China tech stocks cap best rally in over two y...</td>\n",
       "      <td>urn:newsml:reuters.com:20250214:nL1N3P50AJ:2</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>AAPL.O</td>\n",
       "      <td>(Updates closing prices, adds more details and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              headline  \\\n",
       "versionCreated                                                           \n",
       "2025-02-27 13:00:00  RPT-BREAKINGVIEWS-GM illuminates good times be...   \n",
       "2025-02-25 12:52:47  Tesla to acquire parts of insolvent German par...   \n",
       "2025-02-25 01:10:32  RPT-BREAKINGVIEWS-Nissan offers suitors daunti...   \n",
       "2025-02-24 12:00:00  RPT-BREAKINGVIEWS-Nissan offers suitors daunti...   \n",
       "2025-02-21 13:55:05  UPDATE 6-Japan seeks Tesla investment in Nissa...   \n",
       "...                                                                ...   \n",
       "2025-02-14 15:03:57  US STOCKS-Wall St subdued as markets await tar...   \n",
       "2025-02-14 14:04:36  US STOCKS-Wall St set for subdued open as mark...   \n",
       "2025-02-14 12:31:59  US STOCKS-Futures slip as markets await tariff...   \n",
       "2025-02-14 11:50:37  REFILE-FACTBOX-China's AI firms take spotlight...   \n",
       "2025-02-14 08:57:56  China tech stocks cap best rally in over two y...   \n",
       "\n",
       "                                                          storyId sourceCode  \\\n",
       "versionCreated                                                                 \n",
       "2025-02-27 13:00:00  urn:newsml:reuters.com:20250227:nL3N3PH1P3:5    NS:RTRS   \n",
       "2025-02-25 12:52:47  urn:newsml:reuters.com:20250225:nL5N3PG0Y9:7    NS:RTRS   \n",
       "2025-02-25 01:10:32  urn:newsml:reuters.com:20250225:nL3N3PG036:3    NS:RTRS   \n",
       "2025-02-24 12:00:00  urn:newsml:reuters.com:20250224:nL3N3PF0DU:4    NS:RTRS   \n",
       "2025-02-21 13:55:05  urn:newsml:reuters.com:20250221:nL3N3PC0GR:2    NS:RTRS   \n",
       "...                                                           ...        ...   \n",
       "2025-02-14 15:03:57  urn:newsml:reuters.com:20250214:nL4N3P515Y:5    NS:RTRS   \n",
       "2025-02-14 14:04:36  urn:newsml:reuters.com:20250214:nL4N3P512O:5    NS:RTRS   \n",
       "2025-02-14 12:31:59  urn:newsml:reuters.com:20250214:nL4N3P50XC:5    NS:RTRS   \n",
       "2025-02-14 11:50:37  urn:newsml:reuters.com:20250214:nL1N3P50BI:1    NS:RTRS   \n",
       "2025-02-14 08:57:56  urn:newsml:reuters.com:20250214:nL1N3P50AJ:2    NS:RTRS   \n",
       "\n",
       "                        ric                                         full_story  \n",
       "versionCreated                                                                  \n",
       "2025-02-27 13:00:00  TSLA.O  (The author is a Reuters Breakingviews columni...  \n",
       "2025-02-25 12:52:47  TSLA.O  * \\n      Acquisition includes 300 staff, excl...  \n",
       "2025-02-25 01:10:32  TSLA.O  (The author is a Reuters Breakingviews columni...  \n",
       "2025-02-24 12:00:00  TSLA.O  (The author is a Reuters Breakingviews columni...  \n",
       "2025-02-21 13:55:05  TSLA.O  * \\n      Japanese group draws up plans for Te...  \n",
       "...                     ...                                                ...  \n",
       "2025-02-14 15:03:57  AAPL.O  (For a Reuters live blog on U.S., UK and Europ...  \n",
       "2025-02-14 14:04:36  AAPL.O  (For a Reuters live blog on U.S., UK and Europ...  \n",
       "2025-02-14 12:31:59  AAPL.O  (For a Reuters live blog on U.S., UK and Europ...  \n",
       "2025-02-14 11:50:37  AAPL.O  (Refiles to correct transposed letters in Doub...  \n",
       "2025-02-14 08:57:56  AAPL.O  (Updates closing prices, adds more details and...  \n",
       "\n",
       "[262 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_full_story(story_id):\n",
    "    try:\n",
    "        story = rd.news.get_story(story_id, format=rd.news.Format.TEXT)\n",
    "        return story if story else \"Story not available\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {story_id}: {e}\")\n",
    "        return \"Error retrieving story\"\n",
    "\n",
    "dNow = datetime.now().date()\n",
    "maxenddate = dNow - timedelta(days=90) #upto months=15\n",
    "compNews = pd.DataFrame()\n",
    "riclist = ['TSLA.O','AAPL.O'] # can also use Peers, Customers, Suppliers, Monitor, Portfolio to build universe\n",
    "\n",
    "for ric in riclist:\n",
    "    try:\n",
    "        cHeadlines = rd.news.get_headlines(\"R:\" + ric + \" AND Language:LEN AND Source:RTRS AND (Topic:TOP/DEALS OR Topic:TOP/DIGFIN)\", \n",
    "                                           start= str(dNow), \n",
    "                                           end = str(maxenddate), count = 100)\n",
    "        cHeadlines['ric'] = ric\n",
    "        # Corporate Finance: TOP/DEALS, Broker Research / Recommendation: RCH\n",
    "        if len(compNews):\n",
    "            compNews = pd.concat([compNews,cHeadlines])\n",
    "        else:\n",
    "            compNews = cHeadlines\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Apply to all rows\n",
    "compNews[\"full_story\"] = compNews[\"storyId\"].apply(fetch_full_story)\n",
    "\n",
    "compNews2 = pd.DataFrame()\n",
    "riclist = ['TSLA.O','AAPL.O'] # can also use Peers, Customers, Suppliers, Monitor, Portfolio to build universe\n",
    "\n",
    "for ric in riclist:\n",
    "    try:\n",
    "        cHeadlines = rd.news.get_headlines(\"R:\" + ric + \" AND Language:LEN AND Source:RTRS AND (Topic:TOPALL)\", \n",
    "                                           start= str(dNow), \n",
    "                                           end = str(maxenddate), count = 100)\n",
    "        cHeadlines['ric'] = ric\n",
    "        # Corporate Finance: TOP/DEALS, Broker Research / Recommendation: RCH\n",
    "        if len(compNews):\n",
    "            compNews2 = pd.concat([compNews2,cHeadlines])\n",
    "        else:\n",
    "            compNews2 = cHeadlines\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "compNews2[\"full_story\"] = compNews2[\"storyId\"].apply(fetch_full_story)\n",
    "combined_df = pd.concat([compNews, compNews2], axis = 0)\n",
    "combined_df.to_csv('combined_news_updated.csv')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building of RAG Model\n",
    "\n",
    "The RAG model was built with the help of 3 factors, all of which will be dealt with in greater depth below:\n",
    "\n",
    "### Feature 1: Chunking of Documents\n",
    "\n",
    "To facilitate the separation of documents into distinct chunks, RecursiveTextSplitter function was utilised, with an overlap of 100 characters so as to ensure the preservation of context between chunks. Therefore, this enables better understanding of each chunk.\n",
    "\n",
    "### Feature 2: Sentence Embeddings\n",
    "\n",
    "To assign texts to numerical vectors for the machines to process the text, a sentence transformer model was selected to help in semantic similarity search.\n",
    "\n",
    "### Feature 3: Vector Store\n",
    "\n",
    "The use of Facebook Artificial Intelligence Similarity Search (FAISS) was used to store the embeddings for quick retrieval.\n",
    "\n",
    "### Feature 4: Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wjlwi\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.schema import Document\n",
    "from transformers import pipeline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_news_df = pd.read_csv(\"combined_news_updated.csv\")\n",
    "tsla_news = combined_news_df[combined_news_df['ric'] == 'TSLA.O']\n",
    "aapl_news = combined_news_df[combined_news_df['ric'] == 'AAPL.O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>versionCreated</th>\n",
       "      <th>headline</th>\n",
       "      <th>storyId</th>\n",
       "      <th>sourceCode</th>\n",
       "      <th>ric</th>\n",
       "      <th>full_story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-02-27 13:00:00</td>\n",
       "      <td>RPT-BREAKINGVIEWS-GM illuminates good times be...</td>\n",
       "      <td>urn:newsml:reuters.com:20250227:nL3N3PH1P3:5</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>(The author is a Reuters Breakingviews columni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-02-25 12:52:47</td>\n",
       "      <td>Tesla to acquire parts of insolvent German par...</td>\n",
       "      <td>urn:newsml:reuters.com:20250225:nL5N3PG0Y9:7</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>* \\n      Acquisition includes 300 staff, excl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-02-25 01:10:32</td>\n",
       "      <td>RPT-BREAKINGVIEWS-Nissan offers suitors daunti...</td>\n",
       "      <td>urn:newsml:reuters.com:20250225:nL3N3PG036:3</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>(The author is a Reuters Breakingviews columni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-02-24 12:00:00</td>\n",
       "      <td>RPT-BREAKINGVIEWS-Nissan offers suitors daunti...</td>\n",
       "      <td>urn:newsml:reuters.com:20250224:nL3N3PF0DU:4</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>(The author is a Reuters Breakingviews columni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-21 13:55:05</td>\n",
       "      <td>UPDATE 6-Japan seeks Tesla investment in Nissa...</td>\n",
       "      <td>urn:newsml:reuters.com:20250221:nL3N3PC0GR:2</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>* \\n      Japanese group draws up plans for Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2025-02-18 10:56:15</td>\n",
       "      <td>Netherlands to build 1.4 GW battery storage fa...</td>\n",
       "      <td>urn:newsml:reuters.com:20250218:nL6N3P90C3:2</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>AMSTERDAM, Feb 18 - Dutch energy storage firm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2025-02-18 06:29:17</td>\n",
       "      <td>Tesla steps up India hiring after Musk-Modi me...</td>\n",
       "      <td>urn:newsml:reuters.com:20250218:nL3N3P90AQ:1</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>Feb 18 (Reuters) - Elon Musk's Tesla &lt;TSLA.O&gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2025-02-18 04:44:51</td>\n",
       "      <td>Tesla begins mass production of revamped Model...</td>\n",
       "      <td>urn:newsml:reuters.com:20250218:nP8N3O50DP:2</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>BEIJING, Feb 18 (Reuters) - U.S. automaker Tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2025-02-18 03:27:45</td>\n",
       "      <td>Complaints targeting BYD flood Chinese consume...</td>\n",
       "      <td>urn:newsml:reuters.com:20250218:nL3N3P80MF:5</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>BEIJING, Feb 18 (Reuters) - Complaints about B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2025-02-18 02:21:29</td>\n",
       "      <td>FAA fires fewer than 400 workers, transportati...</td>\n",
       "      <td>urn:newsml:reuters.com:20250218:nL2N3P9010:5</td>\n",
       "      <td>NS:RTRS</td>\n",
       "      <td>TSLA.O</td>\n",
       "      <td>By Valerie Volcovici and David Shepardson\\n   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          versionCreated                                           headline  \\\n",
       "0    2025-02-27 13:00:00  RPT-BREAKINGVIEWS-GM illuminates good times be...   \n",
       "1    2025-02-25 12:52:47  Tesla to acquire parts of insolvent German par...   \n",
       "2    2025-02-25 01:10:32  RPT-BREAKINGVIEWS-Nissan offers suitors daunti...   \n",
       "3    2025-02-24 12:00:00  RPT-BREAKINGVIEWS-Nissan offers suitors daunti...   \n",
       "4    2025-02-21 13:55:05  UPDATE 6-Japan seeks Tesla investment in Nissa...   \n",
       "..                   ...                                                ...   \n",
       "157  2025-02-18 10:56:15  Netherlands to build 1.4 GW battery storage fa...   \n",
       "158  2025-02-18 06:29:17  Tesla steps up India hiring after Musk-Modi me...   \n",
       "159  2025-02-18 04:44:51  Tesla begins mass production of revamped Model...   \n",
       "160  2025-02-18 03:27:45  Complaints targeting BYD flood Chinese consume...   \n",
       "161  2025-02-18 02:21:29  FAA fires fewer than 400 workers, transportati...   \n",
       "\n",
       "                                          storyId sourceCode     ric  \\\n",
       "0    urn:newsml:reuters.com:20250227:nL3N3PH1P3:5    NS:RTRS  TSLA.O   \n",
       "1    urn:newsml:reuters.com:20250225:nL5N3PG0Y9:7    NS:RTRS  TSLA.O   \n",
       "2    urn:newsml:reuters.com:20250225:nL3N3PG036:3    NS:RTRS  TSLA.O   \n",
       "3    urn:newsml:reuters.com:20250224:nL3N3PF0DU:4    NS:RTRS  TSLA.O   \n",
       "4    urn:newsml:reuters.com:20250221:nL3N3PC0GR:2    NS:RTRS  TSLA.O   \n",
       "..                                            ...        ...     ...   \n",
       "157  urn:newsml:reuters.com:20250218:nL6N3P90C3:2    NS:RTRS  TSLA.O   \n",
       "158  urn:newsml:reuters.com:20250218:nL3N3P90AQ:1    NS:RTRS  TSLA.O   \n",
       "159  urn:newsml:reuters.com:20250218:nP8N3O50DP:2    NS:RTRS  TSLA.O   \n",
       "160  urn:newsml:reuters.com:20250218:nL3N3P80MF:5    NS:RTRS  TSLA.O   \n",
       "161  urn:newsml:reuters.com:20250218:nL2N3P9010:5    NS:RTRS  TSLA.O   \n",
       "\n",
       "                                            full_story  \n",
       "0    (The author is a Reuters Breakingviews columni...  \n",
       "1    * \\n      Acquisition includes 300 staff, excl...  \n",
       "2    (The author is a Reuters Breakingviews columni...  \n",
       "3    (The author is a Reuters Breakingviews columni...  \n",
       "4    * \\n      Japanese group draws up plans for Te...  \n",
       "..                                                 ...  \n",
       "157  AMSTERDAM, Feb 18 - Dutch energy storage firm ...  \n",
       "158  Feb 18 (Reuters) - Elon Musk's Tesla <TSLA.O> ...  \n",
       "159  BEIJING, Feb 18 (Reuters) - U.S. automaker Tes...  \n",
       "160  BEIJING, Feb 18 (Reuters) - Complaints about B...  \n",
       "161  By Valerie Volcovici and David Shepardson\\n   ...  \n",
       "\n",
       "[134 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to documents\n",
    "documents = [\n",
    "    Document(page_content=row['full_story'],\n",
    "             date=row['versionCreated']) \n",
    "    for _, row in tsla_news.iterrows()\n",
    "]\n",
    "\n",
    "# Chunk documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "split_docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# Initialize embedding model for documents and queries\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n",
    "\n",
    "# Create FAISS vector database\n",
    "vector_db = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# Use a generative model for text generation\n",
    "# llm_model = \"EleutherAI/gpt-neo-2.7B\"  # You can try other models as needed\n",
    "llm_model = \"bigscience/bloom-560m\"\n",
    "llm_pipeline = pipeline(\"text-generation\", model=llm_model, device=0 if torch.cuda.is_available() else -1, \n",
    "                        max_new_tokens=100)\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "# Create the RetrievalQA chain, passing in the LLM and vector database retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, retriever=vector_db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(query):\n",
    "    \"\"\"Function to ask a question using RAG model with extracted context chunks.\"\"\"\n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = vector_db.similarity_search(query, k=3)\n",
    "    \n",
    "    # Extract the context chunks from the retrieved documents\n",
    "    prompt_context = [doc.page_content for doc in retrieved_docs]\n",
    "    # return prompt_context\n",
    "    # Prepare the prompt\n",
    "    context_str = \"\\n\\n\".join(prompt_context)\n",
    "    prompt = f\"\"\"\n",
    "        You are an AI system. Below are relevant news articles with potential relevance:\n",
    "        {context_str}\n",
    "\n",
    "        Based on these excerpts, if the information is insufficient, say \"I do not have enough information.\" Otherwise, answer the following:\n",
    "        \n",
    "        Question: {query}\n",
    "\n",
    "        Answer:\n",
    "    \"\"\".strip()\n",
    "    def remove_consecutive_duplicates(text: str):\n",
    "        # Split the text into sentences using regex\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "        \n",
    "        # Create a list to store non-duplicate sentences\n",
    "        unique_sentences = []\n",
    "        \n",
    "        # Iterate over the sentences and add them to unique_sentences if not a duplicate\n",
    "        for i in range(len(sentences)):\n",
    "            current_sentence = sentences[i].strip()\n",
    "            \n",
    "            # If it's the first sentence or not a duplicate of the previous one, keep it\n",
    "            if i == 0 or current_sentence != sentences[i - 1].strip():\n",
    "                unique_sentences.append(current_sentence)\n",
    "        \n",
    "        # Join the unique sentences back into a single text\n",
    "        return ' '.join(unique_sentences)\n",
    "    \n",
    "    # Generate the model's response\n",
    "    response = llm_pipeline(prompt)[0]['generated_text']\n",
    "    # Find where the 'Question:' part starts\n",
    "    first_qn_pos = response.lower().find('question:')\n",
    "    \n",
    "    answer_start = response.lower().find('answer:')\n",
    "    \n",
    "    # If 'Answer:' is found, slice the text from there\n",
    "    if answer_start != -1:\n",
    "        answer = response[answer_start + len('answer:'):].strip()  # Extract everything after \"Answer:\"\n",
    "        new_answer = remove_consecutive_duplicates(answer)\n",
    "    else:\n",
    "        answer = \"No answer found.\"\n",
    "    \n",
    "    # answer_end = response.lower().find('a:', qn_start)\n",
    "    # answer_end = response.lower().find('question:', first_qn_pos + len('question:'))\n",
    "    \n",
    "    # # If 'Question:' and 'A:' are found, return the text between them\n",
    "    # if first_qn_pos != -1 and answer_end != -1:\n",
    "    #     answer = response[first_qn_pos:answer_end].strip()\n",
    "    # elif first_qn_pos != -1:\n",
    "    #     # If only 'Question:' is found, return everything from 'Question:' onward\n",
    "    #     answer = response[first_qn_pos:].strip()\n",
    "    # else:\n",
    "    #     # If no 'Answer:' part is found, return the whole generated text\n",
    "    #     answer = response.strip()\n",
    "    final_response = f\"Question:{query}\\nAnswer:{new_answer}\"\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:Is Tesla the biggest company selling electric vehicles?\n",
      "Answer:Yes. The company is the largest in the world in terms of sales. The company has a market share of about 50% in the U.S. and Europe. The company has a market share of about 50% in the U.S. and Europe. The company has a market share of about 50% in the U.S. and Europe. The company has a market share of about 50% in the U.S. and Europe. The company has a market share of about 50% in the U.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"Is Tesla the biggest company selling electric vehicles?\"\n",
    "response = ask_question(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The company has a market share of about 50% in the U.S. and Europe. The company has a market share of about 50% in the U.S. and Europe. Claire.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_consecutive_duplicates(text: str):\n",
    "    # Split the text into sentences using regex\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())  # Split on punctuation followed by space\n",
    "    \n",
    "    # Create a list to store non-duplicate sentences\n",
    "    unique_sentences = []\n",
    "    \n",
    "    # Iterate over the sentences and add them to unique_sentences if not a duplicate\n",
    "    for i in range(len(sentences)):\n",
    "        current_sentence = sentences[i].strip()\n",
    "        \n",
    "        # If it's the first sentence or not a duplicate of the previous one, keep it\n",
    "        if i == 0 or current_sentence.lower() != sentences[i - 1].strip().lower():\n",
    "            unique_sentences.append(current_sentence)\n",
    "    \n",
    "    # Join the unique sentences back into a single text\n",
    "    return ' '.join(unique_sentences)\n",
    "\n",
    "text = \"The company has a market share of about 50% in the U.S. and Europe. The company has a market share of about 50% in the U.S. and Europe. Claire.\"\n",
    "remove_consecutive_duplicates(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# import torch\n",
    "# # from transformers import HuggingFacePipeline\n",
    "\n",
    "# # Set up the text generation pipeline\n",
    "# llm_model = \"bigscience/bloom-560m\"\n",
    "# llm_pipeline = pipeline(\"text-generation\", model=llm_model, device=0 if torch.cuda.is_available() else -1, \n",
    "#                         max_new_tokens=100)\n",
    "# llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "# # Function to ask a question given context\n",
    "# def ask_question_with_context(context: str, question: str):\n",
    "#     # Format the prompt with context and question\n",
    "#     prompt = f\"You are an AI bot who is given the following:\\nContext: {context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    "#     response = llm(prompt)\n",
    "    \n",
    "#     # Find where the 'Question:' part starts\n",
    "#     qn_start = response.lower().find('question:')\n",
    "    \n",
    "#     # Find where the 'A:' part starts (indicating the end of the answer)\n",
    "#     answer_end = response.lower().find('a:', qn_start)\n",
    "    \n",
    "#     # If 'Question:' and 'A:' are found, return the text between them\n",
    "#     if qn_start != -1 and answer_end != -1:\n",
    "#         answer = response[qn_start:answer_end].strip()\n",
    "#     elif qn_start != -1:\n",
    "#         # If only 'Question:' is found, return everything from 'Question:' onward\n",
    "#         answer = response[qn_start:].strip()\n",
    "#     else:\n",
    "#         # If no 'Answer:' part is found, return the whole generated text\n",
    "#         answer = response.strip()\n",
    "    \n",
    "#     return answer\n",
    "\n",
    "# # Example context and question\n",
    "# context = \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It was named after the engineer Gustave Eiffel, whose company designed and built the tower.\"\n",
    "# question = \"Where is Eiffel Tower?\"\n",
    "\n",
    "# # Ask the question based on the context\n",
    "# answer = ask_question_with_context(context, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where is Eiffel Tower?\n",
      "Answer: The Eiffel Tower is located in the city of Paris, France. The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It was named after the engineer Gustave Eiffel, whose company designed and built the tower.\n"
     ]
    }
   ],
   "source": [
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The position of 'Q' in 'Question:' is: 74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Question: Where is Eiffel Tower?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_question_q(text: str):\n",
    "    # Find the position of 'Q' in 'Question:'\n",
    "    q_position = text.lower().find('question:')\n",
    "    \n",
    "    # If 'Question:' is found, return the index of the first 'Q'\n",
    "    if q_position != -1:\n",
    "        return q_position  # Returns the index of 'Q' in 'Question:'\n",
    "    else:\n",
    "        return None  # Return None if 'Question:' is not found\n",
    "\n",
    "# Example string\n",
    "example_text = \"You are an AI bot who is given the following:\\nContext: Some context here\\n\\nQuestion: Where is Eiffel Tower?\"\n",
    "\n",
    "# Find the position of the 'Q' in 'Question:'\n",
    "q_index = find_question_q(example_text)\n",
    "\n",
    "# Print the result\n",
    "print(f\"The position of 'Q' in 'Question:' is: {q_index}\")\n",
    "\n",
    "example_text[q_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Evaluation of RAG Model\n",
    "\n",
    "Th\n",
    "\n",
    "### Evaluation of Strengths and Weaknesses\n",
    "\n",
    "#### Strengths\n",
    "\n",
    "#### Weaknesses\n",
    "\n",
    "### Potential Future Work\n",
    "\n",
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
