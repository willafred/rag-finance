{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSA4265 Assignment 2: RAG Generation\n",
    "\n",
    "With the large availability of news available today from different agencies alongside the sheer number of stocks to select from today, it is increasingly difficult for investors to spend time to look through all news articles and reports about the different companies and the performance of their stocks to decide which to buy to maximise their returns. Through the controversial opinions on the performance of stocks, investors tend to rely on analyst reports in terms of scores for established metrics such as Earnings and Sentiments. \n",
    "\n",
    "Therefore, the goal of this assignment is to generate a Retriever-Augmentation-Generation (RAG) model that extracts key information about the overall performance of the stock data based on the recent windows, and providing investment advice to prospective investors about the performance of the stocks. This makes it easier for investors to make an informed decision about the investment in the stocks that have been included in the RAG model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Extraction and Preparation\n",
    "\n",
    "The following section describes the data extraction process and generation of the labelled dataframe. The data obtained was sourced from Refinitiv Workspace.\n",
    "\n",
    "The tickers used in this assignment can be summarised in the table below: \n",
    "\n",
    "| Stock Name | Ticker Symbol |\n",
    "| ---------  | ------------- |\n",
    "| Apple Inc | AAPL |\n",
    "| Amazon.com Inc | AMZN |\n",
    "| Boeing Co | BA |\n",
    "| Berkshire Hathaway Inc Class A | BRKA |\n",
    "| Google | GOOGL |\n",
    "| Goldman-Sachs | GS |\n",
    "| Johnson & Johnson | JNJ |\n",
    "| JPMorgan Chase & Co | JPM |\n",
    "| Coca-Cola Co | KO |\n",
    "| McDonald's Corp | MCD |\n",
    "| Meta Platforms Inc | META |\n",
    "| Morgan Stanley | MS |\n",
    "| Microsoft Corp | MSFT |\n",
    "| NextEra Energy Inc | NEE |\n",
    "| NVIDIA Corp | NVDA |\n",
    "| Pfizer Inc | PFE |\n",
    "| Procter & Gamble Co | PG |\n",
    "| Tesla Inc | TSLA |\n",
    "| Visa Inc | V |\n",
    "| Exxon Mobil Corp | XOM |\n",
    "\n",
    "### Feature 1: Summarisation of Analytic Reports\n",
    "\n",
    "As the documents included in the dataset are relatively long, the use of LLMs was used to summarise the different chunks, and these summarised chunks will then be used for embedding and subsequently to answer the query.\n",
    "\n",
    "### Feature 2: Chunking of Documents\n",
    "\n",
    "To facilitate the separation of documents into distinct chunks, CharacterTextSplitter function was utilised, with an overlap of 100 characters so as to ensure the preservation of context between chunks. Therefore, this enables better understanding of each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_used = [\"aapl\", \"amzn\", \"ba\", \"brka\", \"googl\", \"gs\", \"jnj\", \"jpm\", \"ko\", \"mcd\", \n",
    "               \"meta\", \"ms\", \"msft\", \"nee\", \"nvda\", \"pfe\", \"pg\", \"tsla\", \"v\", \"xom\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_google_vertexai import (\n",
    "    ChatVertexAI,\n",
    "    VectorSearchVectorStore,\n",
    "    VertexAI,\n",
    "    VertexAIEmbeddings,\n",
    ")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from google.cloud import aiplatform\n",
    "import fitz  # pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for VertexAI\n",
    "\n",
    "PROJECT_ID = \"PROJECT-ID\"\n",
    "LOCATION = \"LOCATION\"\n",
    "\n",
    "# For Vector Search Staging\n",
    "GCS_BUCKET = \"BUCKET-ID\"\n",
    "GCS_BUCKET_URI = f\"gs://{GCS_BUCKET}\"\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=GCS_BUCKET_URI)\n",
    "\n",
    "MODEL_NAME = \"gemini-1.5-flash\"\n",
    "GEMINI_OUTPUT_TOKEN_LIMIT = 8192\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-004\"\n",
    "EMBEDDING_TOKEN_LIMIT = 2048\n",
    "\n",
    "TOKEN_LIMIT = min(GEMINI_OUTPUT_TOKEN_LIMIT, EMBEDDING_TOKEN_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarise text using VertexAPI\n",
    "\n",
    "import time\n",
    "def generate_text_summaries(\n",
    "    texts: list[str], summarize_texts: bool = False\n",
    ") -> tuple[list, list]:\n",
    "\n",
    "    # Prompt\n",
    "    prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text for retrieval. \\\n",
    "    These summaries will be embedded and used to retrieve the raw text or table elements. \\\n",
    "    Summarise the issues stemming for the report provided. The report is as shown: {element} \"\"\"\n",
    "    prompt = PromptTemplate.from_template(prompt_text)\n",
    "    empty_response = RunnableLambda(\n",
    "        lambda x: AIMessage(content=\"Error processing document\")\n",
    "    )\n",
    "    # Text summary chain\n",
    "    model = VertexAI(\n",
    "        temperature=0, model_name=MODEL_NAME, max_output_tokens=TOKEN_LIMIT\n",
    "    ).with_fallbacks([empty_response])\n",
    "    summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()\n",
    "\n",
    "    # Initialize empty summaries\n",
    "    text_summaries = []\n",
    "\n",
    "    if texts:\n",
    "        for i in range(len(texts)):\n",
    "            text = texts[i]\n",
    "            if summarize_texts:\n",
    "                # Summarize the current text chunk\n",
    "                summary = summarize_chain.invoke({\"element\": text})\n",
    "                text_summaries.append(summary)\n",
    "            else:\n",
    "                text_summaries.append(text)\n",
    "            print(f\"Chunk {i} summarised, {len(texts)-i} remaining for this stock\")\n",
    "            # Wait for 1 minute after every 3 chunks\n",
    "            if (i + 1) % 4 == 0 and i != len(texts) - 1:\n",
    "                print(\"Waiting for 1 minute before processing the next 4 chunks...\")\n",
    "                time.sleep(60)  # Delay for 1 minute after every 3 chunks\n",
    "    print(\"Summarised!\")\n",
    "    return text_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_used = [\"aapl\", \"amzn\", \"ba\", \"brka\", \"googl\", \"gs\", \"jnj\", \"jpm\", \"ko\", \"mcd\", \n",
    "               \"meta\", \"ms\", \"msft\", \"nee\", \"nvda\", \"pfe\", \"pg\", \"tsla\", \"v\", \"xom\"]\n",
    "\n",
    "stocks_used_dict = dict()\n",
    "\n",
    "for stock in stocks_used:\n",
    "    doc = fitz.open(f\"{stock}_report.pdf\")\n",
    "    text = \"\\n\".join([page.get_text() for page in doc])\n",
    "    \n",
    "    # Extract text from all pages\n",
    "    texts = [page.get_text(\"text\") for page in doc]\n",
    "\n",
    "    # Combine extracted text\n",
    "    full_text = \"\\n\\n\".join(texts)\n",
    "\n",
    "    # Initialize the text splitter, and chunk the reports into more concise summaries\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=1000, chunk_overlap=200\n",
    "    )\n",
    "\n",
    "    # Split text into chunks\n",
    "    texts_4k_token = text_splitter.split_text(full_text)\n",
    "\n",
    "    # Get text summaries from report\n",
    "    text_summaries = generate_text_summaries(\n",
    "        texts_4k_token, summarize_texts=True\n",
    "    )\n",
    "    stocks_used_dict[stock] = text_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building of RAG Model\n",
    "\n",
    "For each ticker's analytics report, the summarised chunks are stored in a list. These lists will then be collated into a dictionary format, where the stock tickers act as the keys of the dictionary for ease of identification. The text summarising function is coded into a loop across all the ticker reports. Following this, the RAG model was built based on the steps which will be described in greater depth below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Stock                                          Summaries\n",
      "0   aapl  [## Summary of Issues from Apple Inc. (0R2V-LN...\n",
      "1   amzn  [## Summary of Issues for AMZN:\\n\\nThe report ...\n",
      "2     ba  [## Summary of Issues for Boeing Co (BA)\\n\\nTh...\n",
      "3   brka  [## Summary of Issues from the Berkshire Hatha...\n",
      "4  googl  [## Summary of Issues from Alphabet Inc. (GOOG...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert stocks_used_dict to a pandas DataFrame, where each stock symbol becomes a row, and its associated summaries become a column\n",
    "stocks_df = pd.DataFrame(list(stocks_used_dict.items()), columns=['Stock', 'Summaries'])\n",
    "\n",
    "# Saving\n",
    "stocks_df.to_csv('stocks_used_summaries.csv', index=False)\n",
    "\n",
    "# Check the resulting DataFrame\n",
    "print(stocks_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: RAG Model Set-Up\n",
    "\n",
    "This section discusses the various methodology involved in the generation of the RAG Model to answer queries based on the impressions of various stocks. To generate the RAG Model, VertexAI was used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Retrieval of Data\n",
    "\n",
    "In this stage, the following steps are applied:\n",
    "\n",
    "1. Checking for duplicates in the summaries for each stock to ensure that the results will not be biased to particular chunks.\n",
    "2. VertexAI vector search index & endpoint is deployed for ease of access to the embedding vectors.\n",
    "3. Creation of Retriever was done with the help of VectorSearchVectorStore with the Vector Search Index ID and Endpoint ID, and the embedding model as textembedding-gecko. This allows the querying of the vector index to retrieve documents that are semantically similar to a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_vector import MultiVectorRetriever\n",
    "from langchain_core.documents import Document\n",
    "import re\n",
    "import uuid\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_google_vertexai import (\n",
    "    ChatVertexAI,\n",
    "    VectorSearchVectorStore,\n",
    "    VertexAI,\n",
    "    VertexAIEmbeddings,\n",
    ")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from google.cloud import aiplatform\n",
    "import fitz  # pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "stocks_used_dict = pd.read_csv('stocks_used_summaries.csv')\n",
    "\n",
    "# Convert the string representation of a list back to an actual list\n",
    "stocks_used_dict['Summaries'] = stocks_used_dict['Summaries'].apply(ast.literal_eval)\n",
    "stocks_used_dict = stocks_used_dict.set_index('Stock')['Summaries'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aapl stock has no duplicate lengths.\n",
      "amzn stock has no duplicate lengths.\n",
      "ba stock has no duplicate lengths.\n",
      "brka stock has no duplicate lengths.\n",
      "googl stock has no duplicate lengths.\n",
      "gs stock has no duplicate lengths.\n",
      "jnj stock has no duplicate lengths.\n",
      "jpm stock has no duplicate lengths.\n",
      "ko stock has summaries with duplicate lengths: {1641}\n",
      "mcd stock has no duplicate lengths.\n",
      "meta stock has no duplicate lengths.\n",
      "ms stock has no duplicate lengths.\n",
      "msft stock has no duplicate lengths.\n",
      "nee stock has no duplicate lengths.\n",
      "nvda stock has no duplicate lengths.\n",
      "pfe stock has no duplicate lengths.\n",
      "pg stock has no duplicate lengths.\n",
      "tsla stock has no duplicate lengths.\n",
      "v stock has no duplicate lengths.\n",
      "xom stock has no duplicate lengths.\n"
     ]
    }
   ],
   "source": [
    "# Checking for duplicates in summaries; after checking, KO does not have duplicates (even though the summaries are of the same length)\n",
    "from collections import Counter\n",
    "\n",
    "for stock, summaries in stocks_used_dict.items():\n",
    "    lengths = [len(s) for s in summaries]  # List of lengths of each summary\n",
    "    length_counts = Counter(lengths)  # Count occurrences of each length\n",
    "    duplicates = {length for length, count in length_counts.items() if count > 1}  # Set of duplicate lengths\n",
    "    if duplicates:\n",
    "        print(f\"{stock} stock has summaries with duplicate lengths: {duplicates}\")\n",
    "    else:\n",
    "        print(f\"{stock} stock has no duplicate lengths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating MatchingEngineIndex\n",
      "Create MatchingEngineIndex backing LRO: projects/954241416931/locations/us-central1/indexes/2117250376771043328/operations/1220752679026819072\n",
      "MatchingEngineIndex created. Resource name: projects/954241416931/locations/us-central1/indexes/2117250376771043328\n",
      "To use this MatchingEngineIndex in another session:\n",
      "index = aiplatform.MatchingEngineIndex('projects/954241416931/locations/us-central1/indexes/2117250376771043328')\n",
      "Creating MatchingEngineIndexEndpoint\n",
      "Create MatchingEngineIndexEndpoint backing LRO: projects/954241416931/locations/us-central1/indexEndpoints/5350764540478881792/operations/3368547488817479680\n",
      "MatchingEngineIndexEndpoint created. Resource name: projects/954241416931/locations/us-central1/indexEndpoints/5350764540478881792\n",
      "To use this MatchingEngineIndexEndpoint in another session:\n",
      "index_endpoint = aiplatform.MatchingEngineIndexEndpoint('projects/954241416931/locations/us-central1/indexEndpoints/5350764540478881792')\n",
      "Deploying index MatchingEngineIndexEndpoint index_endpoint: projects/954241416931/locations/us-central1/indexEndpoints/5350764540478881792\n",
      "Deploy index MatchingEngineIndexEndpoint index_endpoint backing LRO: projects/954241416931/locations/us-central1/indexEndpoints/5350764540478881792/operations/4267015614477893632\n",
      "MatchingEngineIndexEndpoint index_endpoint Deployed index. Resource name: projects/954241416931/locations/us-central1/indexEndpoints/5350764540478881792\n"
     ]
    }
   ],
   "source": [
    "# Creation of endpoints\n",
    "DIMENSIONS = 768  # Dimensions output from textembedding-gecko\n",
    "\n",
    "index = aiplatform.MatchingEngineIndex.create_tree_ah_index(\n",
    "    display_name=\"rag_index\",\n",
    "    dimensions=DIMENSIONS,\n",
    "    approximate_neighbors_count=150,\n",
    "    leaf_node_embedding_count=500,\n",
    "    leaf_nodes_to_search_percent=7,\n",
    "    description=\"RAG LangChain Index\",\n",
    "    index_update_method=\"STREAM_UPDATE\",\n",
    ")\n",
    "\n",
    "DEPLOYED_INDEX_ID = \"rag_index_endpoint\"\n",
    "\n",
    "index_endpoint = aiplatform.MatchingEngineIndexEndpoint.create(\n",
    "    display_name=DEPLOYED_INDEX_ID,\n",
    "    description=\"RAG Index Endpoint\",\n",
    "    public_endpoint_enabled=True,\n",
    ")\n",
    "\n",
    "index_endpoint = index_endpoint.deploy_index(\n",
    "    index=index, deployed_index_id=\"rag_deployed_index1\"\n",
    ")\n",
    "# index_endpoint.deployed_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb import Client\n",
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "import uuid\n",
    "from langchain.schema import Document\n",
    "\n",
    "vectorstore = VectorSearchVectorStore.from_components(\n",
    "    project_id=PROJECT_ID,\n",
    "    region=LOCATION,\n",
    "    gcs_bucket_name=GCS_BUCKET,\n",
    "    index_id=index.name,\n",
    "    endpoint_id=index_endpoint.name,\n",
    "    embedding=VertexAIEmbeddings(model_name=EMBEDDING_MODEL_NAME),\n",
    "    stream_update=True,\n",
    ")\n",
    "\n",
    "# Create the in-memory docstore to store metadata (e.g., stock symbol)\n",
    "docstore = InMemoryStore()\n",
    "\n",
    "# Define the key for document IDs (it could be stock symbols or unique IDs)\n",
    "id_key = \"doc_id\"\n",
    "\n",
    "# Process the stock summaries and add to the vectorstore\n",
    "for stock, summaries in stocks_used_dict.items():\n",
    "    # Generate unique document IDs (or use stock symbols as IDs)\n",
    "    doc_ids = [str(uuid.uuid4()) for _ in summaries]\n",
    "    \n",
    "    # Create Document objects (with summaries and metadata)\n",
    "    summary_docs = [\n",
    "        Document(page_content=s, metadata={id_key: doc_ids[i]})\n",
    "        for i, s in enumerate(summaries)\n",
    "    ]\n",
    "    \n",
    "    # Add documents (summaries) to Chroma vectorstore\n",
    "    vectorstore.add_documents(summary_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Introduction of Query, and Similarity Search\n",
    "\n",
    "In this stage, given a query, the similarity_search function was used to embed the query, and find the chunks that are semantically the closest to the embedded query. Subsequently, these chunks will function as the context, from which it will be fed into the ChatVertexAI LLM to construct a response to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RAG chain with text-only logic\n",
    "def chain_rag(query, num_k, temp = 0):\n",
    "    docs = vectorstore.similarity_search(query, k=num_k)\n",
    "    all_texts = []\n",
    "    for doc in docs:\n",
    "        all_texts.append(doc.page_content)\n",
    "    formatted_texts = \"\\n\".join(all_texts)\n",
    "    \n",
    "    model = ChatVertexAI(\n",
    "        temperature=temp,\n",
    "        model_name=MODEL_NAME,\n",
    "        max_output_tokens=TOKEN_LIMIT,\n",
    "    )\n",
    "    # Prepare the message to send to the model\n",
    "    message = (\n",
    "        \"You are a financial analyst tasked with providing investment advice.\\n\"\n",
    "        \"You will be given text-based data.\\n\"\n",
    "        \"Use this information to provide investment advice related to the user's question.\\n\"\n",
    "        f\"User-provided question: {query}\\n\\n\"\n",
    "        \"Text:\\n\"\n",
    "        f\"{formatted_texts}\\n\\n\"\n",
    "        \"Your response should include:\\n\"\n",
    "        \"- A summary of relevant information from the provided text.\\n\"\n",
    "        \"- An analysis of key financial indicators or trends.\\n\"\n",
    "        \"- A conclusion based on the evidence, explicitly stating how the data supports your recommendation.\\n\"\n",
    "        \"- Citations or references to specific data points where applicable.\"\n",
    "        \"You do not need to repeat the answer twice.\"\n",
    "    )\n",
    "    \n",
    "    # Send the message to the model and get the response\n",
    "    response = model([HumanMessage(content=message)])\n",
    "    final_ans = response.content.replace('*', '')\n",
    "    return final_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Evaluation of RAG Model\n",
    "\n",
    "To evaluate the model, a groundedness check was done to check the validity of the answers itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Method 1: Groundedness Evaluation\n",
    "\n",
    "Following the preparation of the RAG chain to generate based on the queries, checking that the RAG model works was then done by means of a groundedness check to ensure that the answers are not randomly generated. This step is critical in financial applications, as it prevents hallucinations and enhances trust in the generated advice. Through this process, we can also confirm that model outputs align with factual data rather than simply speculations.\n",
    "\n",
    "In this project, I tested it using the methods listed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type 1: Hallucinations\n",
    "In this type, I test for incorrect or fabricated answers, as TSLA does NOT pay dividends.\n",
    "\n",
    "In this example, hallucinations are not observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided text, Tesla (TSLA) does not currently pay a dividend. [2] This means its dividend yield is 0%. [2] The report highlights that Tesla is one of seven companies in its industry group that does not pay a dividend. [2] Additionally, the report lacks information on dividend metrics such as payout, coverage, and yield, making it difficult to assess the company's dividend policy and potential future dividend payments. [5] \n",
      "\n",
      "While the report does not explicitly state why Tesla does not pay a dividend, it does mention that the company has a high accruals ratio, which is the highest within its industry group. [3] This could indicate aggressive accounting practices or a reliance on non-cash earnings, which may be a factor in the company's decision to not pay dividends. \n",
      "\n",
      "Conclusion: Based on the available information, Tesla does not currently pay a dividend and therefore has a dividend yield of 0%. [2] The report lacks information on dividend metrics and does not provide any indication of future dividend payments. [5] Investors seeking dividend income should consider other investment options. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_1 = chain_rag(\"What is Teslaâ€™s (TSLA) dividend yield?\", num_k=1)\n",
    "print(answer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type 2: Comparative Analysis\n",
    "This example tests the reasoning and logic behind the retrieval of the documents. This checks if the RAG model is able to synthesise and process the material thoroughly to make a decision.\n",
    "\n",
    "In this case, a decision was made with reasonable evidence from the analyst reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided information, it's difficult to definitively say which stock investors are more optimistic about, as the data presents a mixed picture for both Pfizer (PFE) and Berkshire Hathaway (BRK.A). \n",
      "\n",
      "Pfizer (PFE):\n",
      "\n",
      " Positive Outlook: PFE has a strong earnings rating of 9, exceeding the Pharmaceuticals industry average (5.3). [Text: \"Pfizer has a strong earnings rating of 9, significantly higher than the Pharmaceuticals industry average of 5.3.\"]\n",
      " Earnings Surprises: PFE has consistently exceeded earnings expectations over the past four quarters. [Text: \"Over the past four quarters, Pfizer has consistently exceeded earnings expectations, reporting four positive surprises.\"]\n",
      " Price Target: Analysts predict a 12-month price target of $30.60, representing a 16.6% increase from the current price. [Text: \"Analysts predict a 12-month price target of $30.60, representing a 16.6% increase from the current price of $26.24.\"]\n",
      "\n",
      "However, there are also concerns:\n",
      "\n",
      " Declining Average Score Trend: PFE's average score has been declining over the past year, suggesting potential volatility. [Text: \"While Pfizer's current average score of 8 places it in the top quartile, the 4-week moving average trend shows a decline over the past year.\"]\n",
      " Lagging Peer Performance: PFE's score has been consistently lower than its peers (MRK, BMY, GILD), indicating a potential competitive disadvantage. [Text: \"Pfizer's score has been consistently lower than its peers (MRK, BMY, GILD) over the past year, indicating a potential competitive disadvantage.\"]\n",
      " Negative Price and Volume Trends: PFE has experienced negative 1-year and 5-year returns, suggesting investor concerns about the company's future prospects. [Text: \"The report reveals a negative 1-year and 5-year return, indicating a declining stock price trend.\"]\n",
      " Mixed Analyst Recommendations: While the mean recommendation is \"Hold,\" there are a significant number of \"Sell\" ratings, indicating a lack of strong confidence in the company's future performance. [Text: \"While the mean recommendation from analysts is \"Hold,\" the distribution of recommendations shows a significant number of \"Sell\" ratings.\"]\n",
      "\n",
      "Berkshire Hathaway (BRK.A):\n",
      "\n",
      " Positive Outlook: BRK.A has a history of positive earnings surprises and a positive analyst outlook. [Text: \"BRK'A has a history of positive earnings surprises, with 3 positive surprises in the last 4 quarters. However, there was also one negative surprise... Analysts are generally bullish on BRK'A's future price, with a mean price target of 784,000.00 USD.\"]\n",
      " Earnings Surprises: BRK.A has a history of positive earnings surprises, with 3 positive surprises in the last 4 quarters. [Text: \"BRK'A has a history of positive earnings surprises, with 3 positive surprises in the last 4 quarters.\"]\n",
      "\n",
      "However, there are also concerns:\n",
      "\n",
      " Estimate Revisions: The consensus estimate for BRK.A's current quarter earnings has decreased over the past 90 days, indicating potential concerns about future performance. [Text: \"The consensus estimate for BRK'A's current quarter earnings has decreased over the past 90 days, indicating potential concerns about future performance.\"]\n",
      " Wide Price Target Range: The price target range for BRK.A is wide, suggesting uncertainty among analysts. [Text: \"However, the price target range is wide, with a high of 836,000.00 USD and a low of 741,000.00 USD.\"]\n",
      "\n",
      "Conclusion:\n",
      "\n",
      "While both PFE and BRK.A have positive aspects, the data suggests that investors may be more cautious about PFE due to its declining average score trend, lagging peer performance, negative price and volume trends, and mixed analyst recommendations. BRK.A, despite recent estimate revisions and a wide price target range, still benefits from a history of positive earnings surprises and a generally bullish analyst outlook. \n",
      "\n",
      "Recommendation:\n",
      "\n",
      "Based on the available data, investors seeking a more optimistic outlook may prefer BRK.A. However, it's important to note that both stocks carry risks and investors should conduct thorough due diligence before making any investment decisions. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_2 = chain_rag(\"It is noted that Pfizer and BRK.A have among the highest positive outlooks. But which stock are investors more optimistic about?\", num_k=5)\n",
    "print(answer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type 3: Giving Logical Advice\n",
    "This example evaluates the ability for the model to assess the risks associated with the stock, and make a decision accordingly.\n",
    "\n",
    "In this case, the evaluation of the Amazon stock is well-balanced, with proper evaluation of the stock risk profile with benchmark stocks such as S&P 500, thereby indicating a decent answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Investing in Amazon: A Risky Yet Potentially Rewarding Proposition\n",
      "\n",
      "Amazon (AMZN) is a company with a high market capitalization and a strong track record of growth. However, the provided report highlights several factors that make it a risky investment. \n",
      "\n",
      "Key Risks:\n",
      "\n",
      " High Correlation with S&P 500: AMZN's high correlation with the S&P 500 (cited in the report) means it offers limited diversification benefits. This implies that during market downturns, AMZN is likely to experience significant losses alongside the broader market.\n",
      " Volatility and Beta: AMZN has a higher beta than the S&P 500, indicating greater volatility. This means its stock price is more susceptible to fluctuations, potentially leading to larger losses during market corrections.\n",
      " High Valuation: AMZN's trailing and forward PE ratios are significantly higher than the market average (36.3 and 32.1 respectively). This suggests the stock is currently priced at a premium, making it vulnerable to a correction if the company fails to meet investor expectations.\n",
      " Declining Performance: The report notes a decline in AMZN's average score, attributed to a decrease in Price Momentum and Insider Trading component scores. Additionally, AMZN has experienced negative returns in the past month and three months, suggesting potential investor concerns about the company's performance.\n",
      " Mixed Analyst Sentiment: While the mean recommendation from analysts is a \"Buy,\" the distribution of recommendations is skewed towards \"Hold\" and \"Sell,\" indicating a mixed outlook among analysts.\n",
      "\n",
      "Potential Advantages:\n",
      "\n",
      " Strong Revenue Generation: Despite the challenges, the report acknowledges that AMZN remains a top performer in its sector and continues to generate strong revenue. This suggests a strong underlying business model with potential for future growth.\n",
      "\n",
      "Conclusion:\n",
      "\n",
      "Based on the provided information, investing in AMZN presents a high-risk, high-reward scenario. While the company has a strong track record and continues to generate significant revenue, its high valuation, declining performance, and high correlation with the broader market make it a volatile investment. \n",
      "\n",
      "Recommendation:\n",
      "\n",
      "Investors with a high risk tolerance and a long-term investment horizon may consider investing in AMZN. However, it is crucial to carefully monitor the company's performance and be prepared for potential volatility. For investors seeking a more conservative approach, diversifying their portfolio with less volatile investments is recommended. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer_3 = chain_rag(\"What are the advantages and disadvantages of investing in Amazon?\", num_k=5)\n",
    "print(answer_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Method 2: LLM Checking\n",
    "\n",
    "Apart from using groundedness check to ensure the validity of the results, I also decided to test the results using VertexAI LLM as well to evaluate the responses of the answers on a scale of 1 to 100. I conducted this using a loop with the specifications of k = [4, 6, 8] and temperature = [0, 0.2, 0.4]. Based on the responses, an overall table for each question will be constructed to compare the quality of responses based on the question to decide the best-performing parameters. This is in hopes of seeing if there are general patterns in parameters that yield better quality responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "num_k = [4,6,8]\n",
    "temp_lst = [0,0.2,0.4]\n",
    "answer1_lst = []\n",
    "answer2_lst = []\n",
    "answer3_lst = []\n",
    "i = 0\n",
    "for k_trial in num_k:\n",
    "    for temp_val in temp_lst:\n",
    "        ans1 = chain_rag(\"Should I invest in JPM now?\", num_k=k_trial, temp=temp_val)\n",
    "        answer1_lst.append(ans1)\n",
    "        ans2 = chain_rag(\"Is TSLA or NEE better positioned for the renewable energy sector?\", num_k=k_trial, temp=temp_val)\n",
    "        answer2_lst.append(ans2)\n",
    "        ans3 = chain_rag(\"Is NVDA a good long-term investment based on recent reports?\", num_k=k_trial, temp=temp_val)\n",
    "        answer3_lst.append(ans3)\n",
    "        if (i + 1) % 2 == 0:\n",
    "                time.sleep(60)  # Delay for 1 minute after every 6 times\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_evaluator(query, ans_list):\n",
    "    score_list = []\n",
    "    model = ChatVertexAI(\n",
    "        temperature=0,\n",
    "        model_name=MODEL_NAME,\n",
    "        max_output_tokens=TOKEN_LIMIT,\n",
    "    )\n",
    "    for i in range(len(ans_list)):\n",
    "        ans = ans_list[i]\n",
    "        # Prepare the message to send to the model\n",
    "        message = (\n",
    "            \"You are a financial analyst tasked with evaluating investment advice.\\n\"\n",
    "            \"Use this information to evaluate to the user's question.\\n\"\n",
    "            f\"User-provided question: {query}\\n\\n\"\n",
    "            \"Text:\\n\"\n",
    "            f\"{ans}\\n\\n\"\n",
    "            \"Please provide a score out of 100 that reflects the overall quality of the answers.\\n\"\n",
    "            \"The score should consider clarity, relevance, depth, and accuracy.\"\n",
    "            \"You do not need an explanation, and you do not need to repeat the answer twice.\"\n",
    "        )\n",
    "    \n",
    "        # Send the message to the model and get the response\n",
    "        response = model([HumanMessage(content=message)])\n",
    "        score_list.append(response.content)\n",
    "        # print(response.content)\n",
    "        if (i + 1) % 3 == 0:\n",
    "            print(\"Waiting for 1 minute before processing the next few chunks...\")\n",
    "            time.sleep(60)  # Delay for 1 minute after every few calls\n",
    "    return score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_lst1 = llm_evaluator(\"Should I invest in JPM now?\", answer1_lst)\n",
    "score_lst2 = llm_evaluator(\"Is TSLA or NEE better positioned for the renewable energy sector?\", answer2_lst)\n",
    "score_lst3 = llm_evaluator(\"Is NVDA a good long-term investment based on recent reports?\", answer3_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results from Evaluation Method 2\n",
    "The following describes the results from the use of the VertexAI LLM to evaluate the answers produced from the RAG Models:\n",
    "\n",
    "##### Question 1\n",
    "| k    | 0    | 0.2 |  0.4    |\n",
    "| :--: | :--: | :-: | :-----: |\n",
    "| 0 |   85   |  85   |   85      |\n",
    "| 0.2 |   85  |  85  |    85    |\n",
    "| 0.4 |   85  |  85  |   85     |\n",
    "\n",
    "##### Question 2\n",
    "| k    | 0    | 0.2 |  0.4    |\n",
    "| :--: | :--: | :-: | :-----: |\n",
    "| 0 |   85   |    85 |  85       |\n",
    "| 0.2 |   90  |  90  |    85    |\n",
    "| 0.4 |   90  |  85  |   90     |\n",
    "\n",
    "##### Question 3\n",
    "| k    | 0    | 0.2 |  0.4    |\n",
    "| :--: | :--: | :-: | :-----: |\n",
    "| 0 |   90   |   85  |    85     |\n",
    "| 0.2 |   85  |  85  |    90    |\n",
    "| 0.4 |   85  |  90  |   85     |\n",
    "\n",
    "Based on the results, no clear pattern is observed as temperature and the k varies for each question. Therefore, for this particular RAG model, there does not appear to be optimal parameters for any given question - rather, the best solution (based on the tested parameters) will vary based on each prompt posed to the model. More research can be done in this field for more parameters to determine if there are optimum parameters for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Overall Evaluation of Model and Conclusion\n",
    "\n",
    "Through the usage of 2 different types of evaluation methods, the quality of the responses produced by the RAG model was relatively similar across the parameters tested, and the answers produced have been shown to be able to provide logical advice, conduct comparative analyses between stocks and companies, and also appear not to have any hallucinations. \n",
    "\n",
    "#### Strengths of Model\n",
    "Firstly, from retrieving relevant documents using vector search to using LLMs such as ChatVertexAI, VertexAI facilitates the entire RAG process. This is extremely key for RAG, as this allows both efficient document retrieval and the ability to generate relevant, context-rich responses to be achieved. The advantages mentioned above is also something commendable about the model built.\n",
    "\n",
    "Next, it also integrates well with Cloud Storage, thereby enabling smooth data pipeline management and faster training cycles for the models used.\n",
    "\n",
    "#### Weaknesses of Model\n",
    "Given the strengths of using VertexAI, there also comes weaknesses of the system. By requiring frequent retrieval operations, RAG models built from Vertex AI can lead to high compute costs, particularly when dealing with large document collections and frequent queries. The cost of both vector search during the retrieval of documents and the generation of text responses can accumulate very quickly. Additionally, given that it will there will be large volumes of queries in subsequent work, the costs of using this service can be very high as well.\n",
    "\n",
    "### Potential Future Work\n",
    "Firstly, as only texts were considered in the RAG model built in this assignment, multi-modal RAG models could be considered since these models will be able to take in images and process the images and graphs to provide a better view of the performance of the stocks. Therefore, this improves the answers from the model.\n",
    "\n",
    "Next, for future works, beyond merely providing an answer or advice to investors, this RAG model has the potential to be adapted to forecast risk factors into the financial sector through the incorporation of more diverse financial indicators. Hence, better predictions can be generated as well.\n",
    "\n",
    "Finally, the measurement of performance of the RAG model can also be improved in terms of comparing the performance. Beyond simply generating and showing evidence, perhaps additional techniques such as the measurement of importance of particular phrases can be done so as to provide greater insight as to why the answer was provided by the RAG model.\n",
    "\n",
    "### Conclusion\n",
    "All in all, this model shows great potential in providing advice to prospective investors about different stocks through the summarisation of the reports in point form, and also through the comparative analysis between stocks. It also does not produce hallucinations which may mislead investors. However, more can be done to enhance the model in the long term to help investors in greater ways such as the use of multi-modal RAG models, and adaptations to achieve other functions investors intend to see such as performance forecasts for the various stocks based on the recent analyst reports."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
